{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence_encoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpucqABGOSm6cazRe9Hq9q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Babayaga-mp4/l2i/blob/master/Sequence_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbxTGOwzknYV"
      },
      "source": [
        "import tensorflow as tf\n",
        "distr = tf.contrib.distributions\n",
        "\n",
        "# import numpy as np\n",
        "# from tqdm import tqdm\n",
        "# import os\n",
        "# import matplotlib.pyplot as plt\n",
        "# from datetime import timedelta\n",
        "#\n",
        "# import time\n",
        "\n",
        "\n",
        "# Embed input sequence [batch_size, seq_length, from_] -> [batch_size, seq_length, to_]\n",
        "def embed_seq(input_seq, from_, to_, is_training, BN=True, initializer=tf.contrib.layers.xavier_initializer()):\n",
        "\twith tf.variable_scope(\"embedding\"):  # embed + BN input set\n",
        "\t\tW_embed = tf.get_variable(\"weights\", [1, from_, to_], initializer=initializer)\n",
        "\t\tembedded_input = tf.nn.conv1d(input_seq, W_embed, 1, \"VALID\", name=\"embedded_input\")\n",
        "\t\tif BN:\n",
        "\t\t\tembedded_input = tf.layers.batch_normalization(embedded_input, axis=2, training=True, name='layer_norm', reuse=None)\n",
        "\t\treturn embedded_input\n",
        "\n",
        "\n",
        "# Apply multihead attention to a 3d tensor with shape [batch_size, seq_length, n_hidden].\n",
        "# Attention size = n_hidden should be a multiple of num_head\n",
        "# Returns a 3d tensor with shape of [batch_size, seq_length, n_hidden]\n",
        "def multihead_attention(inputs, num_units=None, num_heads=16, dropout_rate=0.1, is_training=True):\n",
        "\twith tf.variable_scope(\"multihead_attention\", reuse=None):\n",
        "\t\t# Linear projections\n",
        "\t\tQ = tf.layers.dense(inputs, num_units, activation=tf.nn.relu)  # [batch_size, seq_length, n_hidden]\n",
        "\t\tK = tf.layers.dense(inputs, num_units, activation=tf.nn.relu)  # [batch_size, seq_length, n_hidden]\n",
        "\t\tV = tf.layers.dense(inputs, num_units, activation=tf.nn.relu)  # [batch_size, seq_length, n_hidden]\n",
        "\t\t# Split and concat\n",
        "\t\tQ_ = tf.concat(tf.split(Q, num_heads, axis=2), axis=0)  # [batch_size, seq_length, n_hidden/num_heads]\n",
        "\t\tK_ = tf.concat(tf.split(K, num_heads, axis=2), axis=0)  # [batch_size, seq_length, n_hidden/num_heads]\n",
        "\t\tV_ = tf.concat(tf.split(V, num_heads, axis=2), axis=0)  # [batch_size, seq_length, n_hidden/num_heads]\n",
        "\t\t# Multiplication\n",
        "\t\toutputs = tf.matmul(Q_, tf.transpose(K_, [0, 2, 1]))  # num_heads*[batch_size, seq_length, seq_length]\n",
        "\t\t# Scale\n",
        "\t\toutputs = outputs / (K_.get_shape().as_list()[-1] ** 0.5)\n",
        "\t\t# Activation\n",
        "\t\toutputs = tf.nn.softmax(outputs)  # num_heads*[batch_size, seq_length, seq_length]\n",
        "\t\t# Dropouts\n",
        "\t\toutputs = tf.layers.dropout(outputs, rate=dropout_rate, training=is_training)\n",
        "\t\t# Weighted sum\n",
        "\t\toutputs = tf.matmul(outputs, V_)  # num_heads*[batch_size, seq_length, n_hidden/num_heads]\n",
        "\t\t# Restore shape\n",
        "\t\toutputs = tf.concat(tf.split(outputs, num_heads, axis=0), axis=2)  # [batch_size, seq_length, n_hidden]\n",
        "\t\t# Residual connection\n",
        "\t\toutputs += inputs  # [batch_size, seq_length, n_hidden]\n",
        "\t\t# Normalize\n",
        "\t\toutputs = tf.layers.batch_normalization(outputs, axis=2, training=True, name='ln', reuse=None)  # [batch_size, seq_length, n_hidden]\n",
        "\n",
        "\treturn outputs\n",
        "\n",
        "\n",
        "# Apply point-wise feed forward net to a 3d tensor with shape [batch_size, seq_length, n_hidden]\n",
        "# Returns: a 3d tensor with the same shape and dtype as inputs\n",
        "def feedforward(inputs, num_units=[2048, 512], is_training=True):\n",
        "\twith tf.variable_scope(\"ffn\", reuse=None):\n",
        "\t\t# Inner layer\n",
        "\t\tparams = {\"inputs\": inputs, \"filters\": num_units[0], \"kernel_size\": 1, \"activation\": tf.nn.relu, \"use_bias\": True}\n",
        "\t\toutputs = tf.layers.conv1d(**params)\n",
        "\t\t# Readout layer\n",
        "\t\tparams = {\"inputs\": outputs, \"filters\": num_units[1], \"kernel_size\": 1, \"activation\": None, \"use_bias\": True}\n",
        "\t\toutputs = tf.layers.conv1d(**params)\n",
        "\t\t# Residual connection\n",
        "\t\toutputs += inputs\n",
        "\t\t# Normalize\n",
        "\t\toutputs = tf.layers.batch_normalization(outputs, axis=2, training=True, name='ln', reuse=None)  # [batch_size, seq_length, n_hidden]\n",
        "\treturn outputs\n",
        "\n",
        "\n",
        "# Encode input sequence [batch_size, seq_length, n_hidden] -> [batch_size, seq_length, n_hidden]\n",
        "def encode_seq(input_seq, input_dim, num_stacks, num_heads, num_neurons, is_training, dropout_rate=0.):\n",
        "\twith tf.variable_scope(\"stack\"):\n",
        "\t\tfor i in range(num_stacks):  # block i\n",
        "\t\t\twith tf.variable_scope(\"block_{}\".format(i)):  # Multihead Attention + Feed Forward\n",
        "\t\t\t\tinput_seq = multihead_attention(input_seq, num_units=input_dim, num_heads=num_heads, dropout_rate=dropout_rate, is_training=is_training)\n",
        "\t\t\t\tinput_seq = feedforward(input_seq, num_units=[num_neurons, input_dim], is_training=is_training)\n",
        "\t\treturn input_seq  # encoder_output is the ref for actions [Batch size, Sequence Length, Num_neurons]\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}